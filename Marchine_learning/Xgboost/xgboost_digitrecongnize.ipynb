{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import xgboost as xgb \n",
    "from sklearn.model_selection import train_test_split \n",
    "#记录程序运行时间 \n",
    "import time \n",
    "start_time = time.time() \n",
    "#读入数据 \n",
    "train = pd.read_csv(\"train.csv\") \n",
    "tests = pd.read_csv(\"test.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用sklearn.model_selection进行训练数据集划分，这里训练集和交叉验证集比例为7：3，可以自己根据需要设置 \n",
    "train_xy,val = train_test_split(train, test_size = 0.3,random_state=1) \n",
    "y = train_xy.label # label 单独成为trian目标集\n",
    "X = train_xy.drop(['label'],axis=1) #train集中删去label标签\n",
    "val_y = val.label \n",
    "val_X = val.drop(['label'],axis=1) \n",
    "#xgb矩阵赋值 \n",
    "xgb_val = xgb.DMatrix(val_X,label=val_y) # test集\n",
    "xgb_train = xgb.DMatrix(X, label=y) # train集\n",
    "xgb_test = xgb.DMatrix(tests)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.088231\tval-merror:0.127778\n",
      "Multiple eval metrics have been passed: 'val-merror' will be used for early stopping.\n",
      "\n",
      "Will train until val-merror hasn't improved in 100 rounds.\n",
      "[1]\ttrain-merror:0.066701\tval-merror:0.096508\n",
      "[2]\ttrain-merror:0.057993\tval-merror:0.088333\n",
      "[3]\ttrain-merror:0.052483\tval-merror:0.081587\n",
      "[4]\ttrain-merror:0.05017\tval-merror:0.079365\n",
      "[5]\ttrain-merror:0.048095\tval-merror:0.076111\n",
      "[6]\ttrain-merror:0.046871\tval-merror:0.075317\n",
      "[7]\ttrain-merror:0.046224\tval-merror:0.073333\n",
      "[8]\ttrain-merror:0.04415\tval-merror:0.072302\n",
      "[9]\ttrain-merror:0.043197\tval-merror:0.070317\n",
      "[10]\ttrain-merror:0.042891\tval-merror:0.07\n",
      "[11]\ttrain-merror:0.042041\tval-merror:0.069683\n",
      "[12]\ttrain-merror:0.041429\tval-merror:0.069206\n",
      "[13]\ttrain-merror:0.03966\tval-merror:0.069048\n",
      "[14]\ttrain-merror:0.039626\tval-merror:0.068492\n",
      "[15]\ttrain-merror:0.039456\tval-merror:0.068492\n",
      "[16]\ttrain-merror:0.038503\tval-merror:0.067222\n",
      "[17]\ttrain-merror:0.038401\tval-merror:0.066825\n",
      "[18]\ttrain-merror:0.037925\tval-merror:0.065714\n",
      "[19]\ttrain-merror:0.037415\tval-merror:0.065714\n",
      "[20]\ttrain-merror:0.037381\tval-merror:0.065556\n",
      "[21]\ttrain-merror:0.037109\tval-merror:0.065556\n",
      "[22]\ttrain-merror:0.036667\tval-merror:0.064524\n",
      "[23]\ttrain-merror:0.036497\tval-merror:0.064206\n",
      "[24]\ttrain-merror:0.035986\tval-merror:0.064603\n",
      "[25]\ttrain-merror:0.035646\tval-merror:0.064048\n",
      "[26]\ttrain-merror:0.035442\tval-merror:0.063492\n",
      "[27]\ttrain-merror:0.034762\tval-merror:0.06373\n",
      "[28]\ttrain-merror:0.034762\tval-merror:0.063413\n",
      "[29]\ttrain-merror:0.034558\tval-merror:0.063095\n",
      "[30]\ttrain-merror:0.034524\tval-merror:0.063016\n",
      "[31]\ttrain-merror:0.034592\tval-merror:0.06254\n",
      "[32]\ttrain-merror:0.034388\tval-merror:0.062381\n",
      "[33]\ttrain-merror:0.03432\tval-merror:0.061508\n",
      "[34]\ttrain-merror:0.033776\tval-merror:0.06119\n",
      "[35]\ttrain-merror:0.033537\tval-merror:0.061587\n",
      "[36]\ttrain-merror:0.033367\tval-merror:0.061825\n",
      "[37]\ttrain-merror:0.032857\tval-merror:0.061587\n",
      "[38]\ttrain-merror:0.032619\tval-merror:0.061587\n",
      "[39]\ttrain-merror:0.032721\tval-merror:0.06127\n",
      "[40]\ttrain-merror:0.032585\tval-merror:0.06119\n",
      "[41]\ttrain-merror:0.032245\tval-merror:0.06127\n",
      "[42]\ttrain-merror:0.031769\tval-merror:0.061111\n",
      "[43]\ttrain-merror:0.031599\tval-merror:0.061111\n",
      "[44]\ttrain-merror:0.031327\tval-merror:0.06119\n",
      "[45]\ttrain-merror:0.031088\tval-merror:0.060556\n",
      "[46]\ttrain-merror:0.030714\tval-merror:0.060079\n",
      "[47]\ttrain-merror:0.030374\tval-merror:0.059921\n",
      "[48]\ttrain-merror:0.030442\tval-merror:0.059841\n",
      "[49]\ttrain-merror:0.030612\tval-merror:0.059683\n",
      "[50]\ttrain-merror:0.030374\tval-merror:0.059444\n",
      "[51]\ttrain-merror:0.030102\tval-merror:0.059603\n",
      "[52]\ttrain-merror:0.029728\tval-merror:0.059841\n",
      "[53]\ttrain-merror:0.029456\tval-merror:0.059365\n",
      "[54]\ttrain-merror:0.029558\tval-merror:0.059286\n",
      "[55]\ttrain-merror:0.029218\tval-merror:0.059048\n",
      "[56]\ttrain-merror:0.029252\tval-merror:0.059286\n",
      "[57]\ttrain-merror:0.028946\tval-merror:0.05881\n",
      "[58]\ttrain-merror:0.029116\tval-merror:0.05881\n",
      "[59]\ttrain-merror:0.028878\tval-merror:0.058492\n",
      "[60]\ttrain-merror:0.028912\tval-merror:0.058254\n",
      "[61]\ttrain-merror:0.028912\tval-merror:0.057857\n",
      "[62]\ttrain-merror:0.028878\tval-merror:0.058095\n",
      "[63]\ttrain-merror:0.028673\tval-merror:0.057698\n",
      "[64]\ttrain-merror:0.028571\tval-merror:0.057143\n",
      "[65]\ttrain-merror:0.028333\tval-merror:0.057143\n",
      "[66]\ttrain-merror:0.028265\tval-merror:0.056984\n",
      "[67]\ttrain-merror:0.028061\tval-merror:0.056984\n",
      "[68]\ttrain-merror:0.028061\tval-merror:0.056984\n",
      "[69]\ttrain-merror:0.028027\tval-merror:0.057063\n",
      "[70]\ttrain-merror:0.027925\tval-merror:0.057063\n",
      "[71]\ttrain-merror:0.027823\tval-merror:0.056905\n",
      "[72]\ttrain-merror:0.027823\tval-merror:0.057063\n",
      "[73]\ttrain-merror:0.027619\tval-merror:0.057302\n",
      "[74]\ttrain-merror:0.027245\tval-merror:0.057143\n",
      "[75]\ttrain-merror:0.027313\tval-merror:0.056825\n",
      "[76]\ttrain-merror:0.027109\tval-merror:0.056667\n",
      "[77]\ttrain-merror:0.027041\tval-merror:0.056508\n",
      "[78]\ttrain-merror:0.026735\tval-merror:0.056429\n",
      "[79]\ttrain-merror:0.026395\tval-merror:0.05627\n",
      "[80]\ttrain-merror:0.026497\tval-merror:0.055873\n",
      "[81]\ttrain-merror:0.026259\tval-merror:0.056111\n",
      "[82]\ttrain-merror:0.026327\tval-merror:0.055794\n",
      "[83]\ttrain-merror:0.026463\tval-merror:0.05619\n",
      "[84]\ttrain-merror:0.026463\tval-merror:0.055873\n",
      "[85]\ttrain-merror:0.026531\tval-merror:0.055952\n",
      "[86]\ttrain-merror:0.026293\tval-merror:0.055714\n",
      "[87]\ttrain-merror:0.026224\tval-merror:0.055714\n",
      "[88]\ttrain-merror:0.026293\tval-merror:0.055556\n",
      "[89]\ttrain-merror:0.025952\tval-merror:0.055714\n",
      "[90]\ttrain-merror:0.025748\tval-merror:0.055397\n",
      "[91]\ttrain-merror:0.02568\tval-merror:0.055794\n",
      "[92]\ttrain-merror:0.025612\tval-merror:0.055476\n",
      "[93]\ttrain-merror:0.02568\tval-merror:0.055238\n",
      "[94]\ttrain-merror:0.025612\tval-merror:0.055079\n",
      "[95]\ttrain-merror:0.025578\tval-merror:0.054524\n",
      "[96]\ttrain-merror:0.025306\tval-merror:0.054524\n",
      "[97]\ttrain-merror:0.025272\tval-merror:0.054286\n",
      "[98]\ttrain-merror:0.025306\tval-merror:0.054127\n",
      "[99]\ttrain-merror:0.025374\tval-merror:0.054286\n",
      "[100]\ttrain-merror:0.025068\tval-merror:0.054206\n",
      "[101]\ttrain-merror:0.024932\tval-merror:0.054127\n",
      "[102]\ttrain-merror:0.024796\tval-merror:0.053968\n",
      "[103]\ttrain-merror:0.024626\tval-merror:0.053889\n",
      "[104]\ttrain-merror:0.024388\tval-merror:0.053492\n",
      "[105]\ttrain-merror:0.024388\tval-merror:0.053413\n",
      "[106]\ttrain-merror:0.024286\tval-merror:0.053175\n",
      "[107]\ttrain-merror:0.024014\tval-merror:0.053254\n",
      "[108]\ttrain-merror:0.023946\tval-merror:0.053254\n",
      "[109]\ttrain-merror:0.023776\tval-merror:0.053175\n",
      "[110]\ttrain-merror:0.023741\tval-merror:0.053175\n",
      "[111]\ttrain-merror:0.023707\tval-merror:0.053095\n",
      "[112]\ttrain-merror:0.023503\tval-merror:0.053095\n",
      "[113]\ttrain-merror:0.023435\tval-merror:0.052937\n",
      "[114]\ttrain-merror:0.023231\tval-merror:0.052937\n",
      "[115]\ttrain-merror:0.023197\tval-merror:0.052698\n",
      "[116]\ttrain-merror:0.022993\tval-merror:0.052857\n",
      "[117]\ttrain-merror:0.022925\tval-merror:0.052778\n",
      "[118]\ttrain-merror:0.022789\tval-merror:0.053095\n",
      "[119]\ttrain-merror:0.022789\tval-merror:0.052857\n",
      "[120]\ttrain-merror:0.022687\tval-merror:0.052937\n",
      "[121]\ttrain-merror:0.022619\tval-merror:0.053095\n",
      "[122]\ttrain-merror:0.022517\tval-merror:0.052302\n",
      "[123]\ttrain-merror:0.022347\tval-merror:0.05254\n",
      "[124]\ttrain-merror:0.022245\tval-merror:0.05246\n",
      "[125]\ttrain-merror:0.022211\tval-merror:0.052143\n",
      "[126]\ttrain-merror:0.022279\tval-merror:0.052302\n",
      "[127]\ttrain-merror:0.022211\tval-merror:0.052143\n",
      "[128]\ttrain-merror:0.022075\tval-merror:0.051905\n",
      "[129]\ttrain-merror:0.021905\tval-merror:0.052222\n",
      "[130]\ttrain-merror:0.021735\tval-merror:0.052143\n",
      "[131]\ttrain-merror:0.021701\tval-merror:0.052381\n",
      "[132]\ttrain-merror:0.021735\tval-merror:0.052302\n",
      "[133]\ttrain-merror:0.021565\tval-merror:0.052143\n",
      "[134]\ttrain-merror:0.021599\tval-merror:0.052222\n",
      "[135]\ttrain-merror:0.021361\tval-merror:0.052063\n",
      "[136]\ttrain-merror:0.021259\tval-merror:0.052063\n",
      "[137]\ttrain-merror:0.021327\tval-merror:0.051984\n",
      "[138]\ttrain-merror:0.021224\tval-merror:0.052143\n",
      "[139]\ttrain-merror:0.021156\tval-merror:0.052302\n",
      "[140]\ttrain-merror:0.021122\tval-merror:0.052222\n",
      "[141]\ttrain-merror:0.020952\tval-merror:0.052381\n",
      "[142]\ttrain-merror:0.020918\tval-merror:0.052143\n",
      "[143]\ttrain-merror:0.020918\tval-merror:0.052143\n",
      "[144]\ttrain-merror:0.020714\tval-merror:0.052063\n",
      "[145]\ttrain-merror:0.020714\tval-merror:0.051905\n",
      "[146]\ttrain-merror:0.02068\tval-merror:0.051746\n",
      "[147]\ttrain-merror:0.020646\tval-merror:0.051746\n",
      "[148]\ttrain-merror:0.020578\tval-merror:0.051587\n",
      "[149]\ttrain-merror:0.020442\tval-merror:0.051349\n",
      "[150]\ttrain-merror:0.020374\tval-merror:0.05127\n",
      "[151]\ttrain-merror:0.020272\tval-merror:0.051508\n",
      "[152]\ttrain-merror:0.020204\tval-merror:0.051429\n",
      "[153]\ttrain-merror:0.020034\tval-merror:0.051508\n",
      "[154]\ttrain-merror:0.020102\tval-merror:0.051587\n",
      "[155]\ttrain-merror:0.019932\tval-merror:0.051508\n",
      "[156]\ttrain-merror:0.01983\tval-merror:0.051349\n",
      "[157]\ttrain-merror:0.01966\tval-merror:0.051111\n",
      "[158]\ttrain-merror:0.019626\tval-merror:0.05119\n",
      "[159]\ttrain-merror:0.019592\tval-merror:0.05119\n",
      "[160]\ttrain-merror:0.019558\tval-merror:0.051111\n",
      "[161]\ttrain-merror:0.019456\tval-merror:0.050794\n",
      "[162]\ttrain-merror:0.019456\tval-merror:0.051032\n",
      "[163]\ttrain-merror:0.01949\tval-merror:0.050873\n",
      "[164]\ttrain-merror:0.019524\tval-merror:0.050952\n",
      "[165]\ttrain-merror:0.01949\tval-merror:0.050714\n",
      "[166]\ttrain-merror:0.019456\tval-merror:0.051032\n",
      "[167]\ttrain-merror:0.019422\tval-merror:0.050794\n",
      "[168]\ttrain-merror:0.019218\tval-merror:0.050873\n",
      "[169]\ttrain-merror:0.019252\tval-merror:0.050714\n",
      "[170]\ttrain-merror:0.019082\tval-merror:0.050635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[171]\ttrain-merror:0.01898\tval-merror:0.050556\n",
      "[172]\ttrain-merror:0.018946\tval-merror:0.050397\n",
      "[173]\ttrain-merror:0.018912\tval-merror:0.050159\n",
      "[174]\ttrain-merror:0.019014\tval-merror:0.050159\n",
      "[175]\ttrain-merror:0.018707\tval-merror:0.050079\n",
      "[176]\ttrain-merror:0.018741\tval-merror:0.05\n",
      "[177]\ttrain-merror:0.018707\tval-merror:0.049921\n",
      "[178]\ttrain-merror:0.018707\tval-merror:0.049841\n",
      "[179]\ttrain-merror:0.018707\tval-merror:0.049921\n",
      "[180]\ttrain-merror:0.018571\tval-merror:0.049841\n",
      "[181]\ttrain-merror:0.018503\tval-merror:0.049762\n",
      "[182]\ttrain-merror:0.018401\tval-merror:0.049683\n",
      "[183]\ttrain-merror:0.018367\tval-merror:0.049762\n",
      "[184]\ttrain-merror:0.018401\tval-merror:0.049524\n",
      "[185]\ttrain-merror:0.018299\tval-merror:0.049603\n",
      "[186]\ttrain-merror:0.018265\tval-merror:0.049603\n",
      "[187]\ttrain-merror:0.018231\tval-merror:0.049603\n",
      "[188]\ttrain-merror:0.018231\tval-merror:0.049524\n",
      "[189]\ttrain-merror:0.018095\tval-merror:0.049524\n",
      "[190]\ttrain-merror:0.018027\tval-merror:0.049444\n",
      "[191]\ttrain-merror:0.017959\tval-merror:0.049206\n",
      "[192]\ttrain-merror:0.017891\tval-merror:0.049365\n",
      "[193]\ttrain-merror:0.017857\tval-merror:0.049365\n",
      "[194]\ttrain-merror:0.017891\tval-merror:0.049206\n",
      "[195]\ttrain-merror:0.017721\tval-merror:0.049286\n",
      "[196]\ttrain-merror:0.017687\tval-merror:0.049365\n",
      "[197]\ttrain-merror:0.017585\tval-merror:0.049444\n",
      "[198]\ttrain-merror:0.017415\tval-merror:0.049365\n",
      "[199]\ttrain-merror:0.017551\tval-merror:0.049524\n",
      "best best_ntree_limit 192\n"
     ]
    }
   ],
   "source": [
    "params={ \n",
    "    'booster':'gbtree', \n",
    "    'objective': 'multi:softmax', #多分类的问题 \n",
    "    'num_class':10, # 类别数，与 multisoftmax 并用 \n",
    "    'gamma':0.1, # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。 \n",
    "    'max_depth':12, # 构建树的深度，越大越容易过拟合 \n",
    "    'lambda':2, # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。 \n",
    "    'subsample':0.7, # 随机采样训练样本 \n",
    "    'colsample_bytree':0.7, # 生成树时进行的列采样 \n",
    "    'min_child_weight':3, # 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言 \n",
    "    #，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。 \n",
    "    #这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。\n",
    "    'silent':0 ,#设置成1则没有运行信息输出，最好是设置为0. \n",
    "    'eta': 0.007, # 如同学习率 \n",
    "    'seed':1000, \n",
    "    #'nthread':7,# cpu 线程数 \n",
    "    'gpu_id': 0,\n",
    "    'max_bin': 128,\n",
    "    'tree_method': 'gpu_hist',\n",
    "    #'eval_metric': 'auc' \n",
    "} \n",
    "\n",
    "plst = list(params.items()) \n",
    "num_rounds = 200 # 迭代次数 \n",
    "watchlist = [(xgb_train, 'train'),(xgb_val, 'val')] \n",
    "#训练模型并保存 \n",
    "# early_stopping_rounds 当设置的迭代次数较大时，early_stopping_rounds 可在一定的迭代次数内准确率没有提升就停止训练 \n",
    "model = xgb.train(plst, xgb_train, num_rounds, watchlist,early_stopping_rounds=100) \n",
    "model.save_model('xgbdigit.model') # 用于存储训练出的模型 \n",
    "print(\"best best_ntree_limit\", model.best_ntree_limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost success! \n",
      " cost time: 685.0299446582794 (s)......\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(xgb_test,ntree_limit=model.best_ntree_limit) \n",
    "np.savetxt('xgb_submission.csv',\n",
    "           np.c_[range(1,len(tests)+1),preds],delimiter=',',\n",
    "           header='ImageId,Label',comments='',fmt='%d') \n",
    "#输出运行时长 \n",
    "cost_time = time.time()-start_time \n",
    "print(\"xgboost success!\",'\\n',\"cost time:\",cost_time,\"(s)......\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
